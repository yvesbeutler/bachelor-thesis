\chapter{Performance Metrics}

All of the following baseline attempts are measured with a total of 967 messages. Due to the different qualities of each message
these numbers would change by adding more samples. Consider chapter \ref{chap:formulas} for an explanation of the different \acrlong{kpi}s.
The final performance measurements for each entity type are compared against each other.

\section{SpaCy}

\begin{table}[ht!]
    \centering
    \begin{tabular}{|p{6em}|p{3em}|}
        \hline
        Accuracy & 0.946 \\
        \hline
        Precision & 0.444 \\
        \hline
        Recall & 0.533 \\
        \hline
        \textbf{F1 Score} & \textbf{0.485} \\
        \hline
    \end{tabular}
    \caption{Spacy KPIs}
    \label{tbl:perf-spacy}
\end{table}

The next two tables show how the spaCy model performs with only one given named-entity type. Due to its training corpus it's not very
surprising that spaCy struggles more with addresses rather than people.

\begin{table}[ht!]
    \begin{minipage}{.5\linewidth}
        \centering
        \begin{tabular}{|p{6em}|p{3em}|}
            \hline
            Accuracy & 0.955 \\
            \hline
            Precision & 0.405 \\
            \hline
            Recall & 0.685 \\
            \hline
            \textbf{F1 Score} & \textbf{0.509} \\
            \hline
        \end{tabular}
        \caption{Spacy (only PER)}
        \label{tbl:perf-spacy-per}
    \end{minipage}%
    \begin{minipage}{.5\linewidth}
        \centering
        \begin{tabular}{|p{6em}|p{3em}|}
            \hline
            Accuracy & 0.933 \\
            \hline
            Precision & 0.039 \\
            \hline
            Recall & 0.158 \\
            \hline
            \textbf{F1 Score} & \textbf{0.063} \\
            \hline
        \end{tabular}
        \caption{Spacy (only LOC)}
        \label{tbl:perf-spacy-loc}
    \end{minipage}
\end{table}

\section{Regex Baseline}

Chapter \ref{chap:regex-model} provides more information about the different enhancements.

\begin{table}[ht]
    \centering
    \begin{tabular}{|L{16em}|C{3em}|C{3em}|C{3em}|C{3em}|}
        \hline
        \textbf{Enhancement} & \textbf{Acc} & \textbf{Prec} & \textbf{Rec} & \textbf{F1} \\ [1ex]
        \hline
        1 - Add dictionary lookup & 0.774 & 0.146 & 0.733 & 0.243 \\ [0.2ex]
        \hline
        2 - Remove last names dictionary & 0.953 & 0.582 & 0.401 & 0.475 \\ [0.2ex]
        \hline
        3 - Clean up last names & 0.948 & 0.432 & 0.723 & 0.541 \\ [0.2ex]
        \hline
        4 - Add uppercase constraint & 0.953 & 0.487 & 0.722 & 0.582 \\ [0.2ex]
        \hline
        5 - Escape \gls{diacritic}s & 0.953 & 0.486 & 0.736 & 0.585 \\ [0.2ex]
        \hline
        6 - Add variants (e.g. umlauts) & 0.952 & 0.503 & 0.758 & 0.605 \\ [0.2ex]
        \hline
        7 - Add previous and next tokens & 0.954 & 0.504 & 0.761 & 0.606 \\ [0.2ex]
        \hline
        8 - Clean up first- and last names & 0.982 & 0.773 & 0.752 & 0.762 \\ [0.2ex]
        \hline
        9 - Replace addresses with regex & 0.98 & 0.848 & 0.732 & \textbf{0.786} \\ [0.2ex]
        \hline
    \end{tabular}
    \caption{Regex baseline KPIs}
    \label{tbl:perf-regex}
\end{table}

\begin{table}[ht!]
    \begin{minipage}{.5\linewidth}
        \centering
        \begin{tabular}{|p{6em}|p{3em}|}
            \hline
            Accuracy & 0.984 \\
            \hline
            Precision & 0.737 \\
            \hline
            Recall & 0.885 \\
            \hline
            \textbf{F1 Score} & \textbf{0.804} \\
            \hline
        \end{tabular}
        \caption{Regex (only PER)}
        \label{tbl:perf-regex-per}
    \end{minipage}%
    \begin{minipage}{.5\linewidth}
        \centering
        \begin{tabular}{|p{6em}|p{3em}|}
            \hline
            Accuracy & 0.951 \\
            \hline
            Precision & 0.111 \\
            \hline
            Recall & 0.334 \\
            \hline
            \textbf{F1 Score} & \textbf{0.166} \\
            \hline
        \end{tabular}
        \caption{Regex (only LOC)}
        \label{tbl:perf-regex-loc}
    \end{minipage}
\end{table}

\subsection{Excluded Ambiguous Names}
\label{lst:excluded-names}

The following list shows all values which aren't common names or which may be names but are ambiguous. These values are removed from the naming dictionaries which
are used by the regex baseline model.

\begin{multicols}{4}
    \begin{itemize}
        \item mobiliar
        \item mobi
        \item immobilien
        \item safari
        \item franken
        \item guten
        \item leider
        \item min
        \item link
        \item weiss
        \item herr
        \item app
        \item kunde
        \item dame
        \item damen
        \item frau
        \item gerne
        \item sport
        \item firma
        \item herren
        \item liebe
        \item schaden
        \item grund
        \item person
        \item kinder
        \item mio
        \item juni
        \item bern
        \item mail
        \item post
        \item mar
        \item sun
        \item fall
        \item ort
        \item hand
        \item mon
        \item wed
        \item may
        \item gruss
        \item abend
        \item mai
        \item juni
        \item juli
        \item phone
        \item spray
        \item buchung
        \item freitag
        \item montag
        \item monday
        \item fehler
        \item glueck
        \item uri
        \item seite
        \item auto
        \item pin
        \item biel
        \item you
        \item helvetia
        \item weg
        \item art
        \item termine
        \item chance
        \item merci
        \item stecker
        \item preis
        \item partner
        \item restaurant
        \item handy
        \item zurich
        \item schlechten
        \item privat
        \item frische
        \item kan
        \item name
    \end{itemize}
\end{multicols}

\chapter{Source Code}

This chapter contains source code snippets for the preprocessing work, the two baseline approaches, and the final solution.
Only the important parts are covered in this section. The complete source code was handed to the supervising professor
before the submission deadline.


\section{Baseline Approaches}

\subsection{spaCy}

\begin{lstlisting}[language=Python, label={code:tokenizer}, caption=Custom whitespace tokenizer]
class WhitespaceTokenizer(object):
    """
    A simple whitespace tokenizer to split texts the same way like
    string.split(' ') does. This class can be set as default
    tokenizer for a spaCy instance.
    """
    def __init__(self, vocab):
        self.vocab = vocab

    def __call__(self, text):
        words = text.split(' ')
        # All tokens 'own' a subsequent space character in this tokenizer
        spaces = [True] * len(words)
        return Doc(self.vocab, words=words, spaces=spaces)
\end{lstlisting}

\section{Deep Learning}

\subsection{Sliding Window}

\begin{lstlisting}[language=Python, label={code:sliding-window}, caption=Sliding window implementation]
def sliding_window(sequences, window_size=5, placeholder='', flatten=True):
    """
    Creates windows of the exact same size, first and last windows
    will be padded with a placeholder. The relevant token of each
    window is placed in the middle. Flattens the list by default.
    """
    half = int(window_size / 2)
    results = []

    for sequence in sequences:

        tokens = sequence[0]
        labels = sequence[1]

        length = len(tokens)
        windows = []

        # create windows
        for idx in range(length):
            start = idx - half
            stop = idx + 1 + half
            windows.append([tokens[max(0, start):stop], labels[idx]])

        # add padding for first windows
        for idx, val in enumerate(range(half, 0, -1)):
            tmp = windows[idx][0]
            for i in range(val):
                tmp = [placeholder] + tmp

            windows[idx][0] = tmp

        # add padding for last windows
        for val, idx in enumerate(range(length-half, length)):
            tmp = windows[idx][0]
            for i in range(val+1):
                tmp = tmp + [placeholder]

            windows[idx][0] = tmp

        results.append(windows)

    if flatten:
        results = [item for sublist in results for item in sublist]

    return results
\end{lstlisting}

\subsection{Keras Tokenizer}

The Keras tokenizer allows you to define the \emph{OOV} token during initialisation. With the \verb|filter| option you can define which characters the
tokenizer should filter from the tokens. The default filter would handle "\emph{Hello}" and "\emph{Hello,}" as the same token. For not losing punctuation
the \verb|filter| parameter needs to be set to an empty string.

\begin{lstlisting}[language=Python, label={code:keras-tokenizer}, caption=Fitting the Keras tokenizer]
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(oov_token='<OOV>', filters='')

# create a vocabulary based on the training set
tokenizer.fit_on_texts(train_sentences)

# create sequences of IDs
sequences = tokenizer.texts_to_sequences(test_sentences)
\end{lstlisting}
